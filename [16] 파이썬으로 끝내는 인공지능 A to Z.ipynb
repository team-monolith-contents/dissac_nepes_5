{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"padding: 15px; border: 5px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #3c763d; background-color: #dff0d8; border-color: #d6e9c6; font-weight: bold;\">\n",
    "    <br><br>\n",
    "    <div style=\"font-weight: bold; font-size: 40px\">파이썬으로 끝내는 인공지능 A to Z</div>\n",
    "    <div style=\"font-weight: bold; font-size: 20px\">[16] 성장하는 인공지능: 강화학습 알아보기</div>\n",
    "    <hr style=\"width:80%;text-align:left;margin-left:0;border:0.5px solid green\">\n",
    "    <br>\n",
    "    &#x2022; 강화학습의 학습 원리를 이해할 수 있다.<br>\n",
    "    &#x2022; 강화학습이 사용되는 다양한 사례를 탐색할 수 있다.<br>\n",
    "    &#x2022; 강화학습을 이용하여 실제 게임을 학습시킬 수 있다.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<div style=\"padding: 15px; border: 5px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #3c763d; border-color: #d6e9c6; font-weight: bold;\">\n",
    "<h2 style='font-weight: bold'>1. 강화학습이 무엇인가요?</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2sJRHyaQ-TCl"
   },
   "source": [
    "### **1. 강화학습의 원리**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OPQhJ4HYuBHu"
   },
   "source": [
    "강화학습은 **시행착오**를 통해 주어진 상태에서 최적의 행동을 선택하는 학습 방법이에요.  \n",
    "강화학습에서는 지도/비지도 기계학습과 달리, 아무런 데이터가 주어지지 않아요.  \n",
    "대신 주어진 상태에서 행동의 결과에 대한 **보상**을 에이전트에게 주어요.   \n",
    "에이전트는 행동과 보상에 대한 정보를 바탕으로, 어떤 행동을 취해야 가장 큰 보상을 가져올지 스스로 학습하는 것이지요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "O3kZwpNLuBHu"
   },
   "source": [
    "게임을 하는 사람이 게임 실력을 키우는 과정을 통해, 강화 학습의 원리를 자세하게 이해해보아요.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th><img src=\"https://tmn-bucket-materials-all.s3.ap-northeast-2.amazonaws.com/image/ai/AI-09-01.png\" width=\"500\"></th>\n",
    "    </tr>\n",
    "<tr>\n",
    "    <th>강화학습의 원리</th>\n",
    "</tr>\n",
    "</table>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kkMfDlFJuBHu"
   },
   "source": [
    "에이전트는 둘러싸고 있는 환경과 상호작용하는 행동의 주체를 의미해요.  \n",
    "환경은 에이전트를 둘러싸고 있는 것들이에요.  \n",
    "상태는 에이전트에 대한 상태를 숫자로 표현한 것이에요.  \n",
    "행동은 에이전트가 실제 행동한 내용이에요.  \n",
    "보상은 에이전트가 행동한 결과로 받게 되는 것이에요.  \n",
    "정책은 행동에 따른 보상을 기반으로 에이전트가 행동하는 방향이에요.  \n",
    "\n",
    "> 에이전트는 게임이라는 환경에서, 어떻게 행동해야 더 많은 보상을 얻을지 학습해요.   \n",
    "> 학습을 통해, 에이전트는 더 많은 보상을 얻기 위한 정책을 수립하는 것이지요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EJmN5WE_1Ev9"
   },
   "source": [
    "### **2. 강화학습과 지도/비지도학습**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WSk9LaRF1Ev9"
   },
   "source": [
    "지난 4단원에서 인공지능을 활용 목적에 따라 지도학습, 비지도학습, 강화학습으로 나누었었어요.  \n",
    "지도학습은 회귀/분류를 위해, 비지도학습은 그룹화를 위해, 강화학습은 더 좋은 선택을 하기 위해 사용한다고 했었어요.  \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th><img src=\"https://tmn-bucket-materials-all.s3.ap-northeast-2.amazonaws.com/image/ai/AI-09-02.png\" width=\"500\"></th>\n",
    "    </tr>\n",
    "<tr>\n",
    "    <th>강화학습과 지도/비지도학습</th>\n",
    "</tr>\n",
    "</table>  \n",
    "\n",
    "강화학습은 활용 목적이 지도/비지도학습과 크게 다른 만큼, 학습 형태도 다른 부분이 있어요.  \n",
    "우선, 지도/비지도학습이 데이터가 이미 주어진 **정적(static)** 환경에서 학습이 진행되었다면,  \n",
    "강화학습은 데이터 없이 보상을 얻으면서 학습하는 **동적(dynamic)** 환경에서 진행되어요.   \n",
    "강화학습은 동적 상태에서 데이터를 수집하는 과정까지 함께 포함된 알고리즘이에요.  \n",
    "\n",
    "강화학습은 데이터 없이 보상만을 가지고 학습하기 때문에,  \n",
    "학습시키는 게임의 규칙을 모르는 상황에서도 학습할 수 있어요.  \n",
    "그렇기 때문에 복잡한 상황에서 최선의 동작을 찾고자 할 때 강화학습이 많이 사용되어요.  \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th><img src=\"https://tmn-bucket-materials-all.s3.ap-northeast-2.amazonaws.com/image/ai/AI-09-03.png\" width=\"500\"></th>\n",
    "    </tr>\n",
    "<tr>\n",
    "    <th>강화학습의 특징</th>\n",
    "</tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "T95F0kWMuBHv"
   },
   "source": [
    "### **3. 강화학습의 생활 속 사례**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uTPyEUeTuBHv"
   },
   "source": [
    "강화학습은 실제 생활 속에서 다양하게 사용될 수 있어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Nwp9BpAtuBHv"
   },
   "source": [
    "예시 1: 인공지능 골키퍼가 상대 선수의 축구공을 막는다.   \n",
    "\n",
    "<a href=\"https://youtu.be/7Yc6ZHixgRk\"><button style=\"width:100px; height:50px\">링크</button></a>\n",
    "\n",
    "- 에이전트 : 골키퍼\n",
    "- 환경 : 축구장\n",
    "- 행동 : 상대가 찬 공을 막기 위해 적절한 위치로 이동한다.\n",
    "- 보상 : 상대가 찬 공이 골대에 들어가지 않으면 득점을 막을 수 있다.\n",
    "- 상태 : 상대가 차는 축구공을 막기 위한 골대의 골키퍼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "X4WRR0JYuBHw"
   },
   "source": [
    "예시 2: 강화학습을 통해 볼링공이 볼링을 맞춥니다.   \n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=nReMgotclXU\"><button style=\"width:100px; height:50px\">링크</button></a>\n",
    "\n",
    "- 에이전트 : 볼링공\n",
    "- 환경 : 볼링장\n",
    "- 행동 : 볼링공의 위치, 스핀을 달리하여 굴리기\n",
    "- 보상 : 볼링핀을 시간 내에 맞추면 상을 준다. 못 맞히거나 시간을 초과하면 벌을 준다.\n",
    "- 상태 : 볼링공과 볼링핀의 거리, 볼링공의 위치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<div style=\"padding: 15px; border: 5px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #3c763d; border-color: #d6e9c6; font-weight: bold;\">\n",
    "<h2 style='font-weight: bold'>2. 강화학습 실습해보기</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7mDLmcfgYSjf"
   },
   "source": [
    "### **1. Frozen Lake 알아보기**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FYUKSmRC1Ev_"
   },
   "source": [
    "Frozen Lake는 강화학습 분야에서 자주 사용되는 간단한 환경 중 하나입니다.<br>\n",
    "이 게임은 마치 얼어붙은 호수 위를 걷는 것과 같은 상황을 모방한 것으로, 에이전트(agent)가 시작 지점에서 출발하여 목표 지점까지 안전하게 도달하는 것을 목표로 합니다.<br>\n",
    "\n",
    "게임 규칙은 아래와 같습니다.\n",
    "\n",
    "1. 게임 보드는 격자로 구성되어 있으며, 각 격자 셀은 시작 지점, 목표 지점, 얼어붙은 지면, 그리고 보상(보상이 있는 지면과 없는 지면)으로 나뉩니다.\n",
    "2. 에이전트는 시작 지점에서 출발하며, 각 단계마다 상, 하, 좌, 우 네 가지 방향 중 하나를 선택하여 움직일 수 있습니다.\n",
    "3. 목표 지점에 도착하면 게임이 종료됩니다.\n",
    "4. 에이전트가 구멍에 빠지면 게임이 종료됩니다.\n",
    "5. 게임 보드의 경계를 넘어가려고 할 때에는 이동이 불가능합니다.\n",
    "6. 게임의 목표는 얼어붙은 호수를 피해 목표 지점까지 도달하는 최적의 경로를 학습하는 것입니다.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th><img src=\"https://tmn-bucket-materials-all.s3.ap-northeast-2.amazonaws.com/image/ai/AI-09-04.PNG\" width=\"300\"></th>\n",
    "    </tr>\n",
    "<tr>\n",
    "    <th>Frozen Lake</th>\n",
    "</tr>\n",
    "</table>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div style=\"padding: 15px; border: 5px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;  border-color: #faebcc; font-weight: bold;\">\n",
    "    <div style=\"font-weight: bold; font-size: 20px\">✏️ [문제1]</div>\n",
    "    <br>\n",
    "Frozen Lake에서 강화학습의 각 요소는 무엇에 해당되는지 작성해보아요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "👉 \n",
    "👉 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div style=\"padding: 15px; border: 5px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;  border-color: #faebcc; font-weight: bold;\">\n",
    "    <div style=\"font-weight: bold; font-size: 20px\">✏️ [문제2]</div>\n",
    "    <br>\n",
    "여러분이 Frozen Lake의 맵을 모른다고 하면, 목표에 도착하기 위해 어떤 방법을 사용할지 이야기해보아요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "👉 \n",
    "👉 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5v0Kf1t71Ev_"
   },
   "source": [
    "### **2. Frozen Lake 학습시키기**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jZLbQcuV1Ev_"
   },
   "source": [
    "아래의 코드를 실행하여 에이전트가 어떻게 학습하는지 알아봅시다.\n",
    "\n",
    "**학습횟수**는 총 학습 횟수를 나타냅니다.(최대 10만 번 까지 가능합니다.)<br>\n",
    "**가장 오른쪽의 숫자**는 현재까지 학습한 횟수를 나타냅니다.<br>\n",
    "**학습하기 버튼**을 통해 학습을 시작할 수 있습니다.<br>\n",
    "학습이 모두 종료된 이후 **테스트하기 버튼**을 통해 학습된 에이전트를 테스트할 수 있습니다.<br>\n",
    "\n",
    "1000번 학습할 때 마다 학습과정을 보여줍니다.<br>\n",
    "1000번 학습할 때 마다 **단계당 평균 보상**를 그래프로 나타냅니다.<br>\n",
    "여기서는 도착지점에서만 1의 보상을 주기 때문에 5번 만에 도착지점에 도착하면 1/5 = 0.2 의 **단계당 평균 보상** 값을 가집니다.<br>\n",
    "(평균 리워드가 높을수록 더 적은 횟수 만에 목표점에 도달한 것입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Frozen Lake 실행을 위해 필요한 라이브러리들을 설치합니다.\n",
    "!pip install gym\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "error_code": "from CodleAI import Agent\n\nmap = [\"SFFF\",\n       \"FHFH\",\n       \"FFFH\",\n       \"HFFG\"]\n\nAgent(map)",
    "executionInfo": {
     "elapsed": 7103,
     "status": "ok",
     "timestamp": 1688053560332,
     "user": {
      "displayName": "성무열",
      "userId": "14501712316857642086"
     },
     "user_tz": -540
    },
    "id": "ihU831FD1MMF",
    "outputId": "f600c514-0c7c-4401-d09f-1c9b44ba9332",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from CodleAI import AIProject3\n",
    "\n",
    "map = [\"SFFF\",\n",
    "       \"FHFH\",\n",
    "       \"FFFH\",\n",
    "       \"HFFG\"]\n",
    "\n",
    "AIProject3(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jZLbQcuV1Ev_",
    "tags": []
   },
   "source": [
    "map 변수의 값을 수정하여 맵의 구성을 바꿀 수 있습니다.<br>\n",
    "각각의 알파벳은 각각에 해당하는 구조를 나타냅니다.<br>\n",
    "\n",
    "**S:** 시작지점<br>\n",
    "**F:** 얼음<br>\n",
    "**H:** 구멍<br>\n",
    "**G:** 목표지점<br>\n",
    "\n",
    "map을 바꿔서 에이전트가 더 복잡한 호수를 탈출할 수 있도록 해봅시다.\n",
    "(map이 너무 크면 에이전트가 잘 학습을 하지 못할 수 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "error_code": "from CodleAI import Agent\n\nmap = [\"SFFFFF\",\n       \"FHFHHF\",\n       \"FHFFHF\",\n       \"HFFFFG\"]\n\nAgent(map)",
    "executionInfo": {
     "elapsed": 7103,
     "status": "ok",
     "timestamp": 1688053560332,
     "user": {
      "displayName": "성무열",
      "userId": "14501712316857642086"
     },
     "user_tz": -540
    },
    "id": "ihU831FD1MMF",
    "outputId": "f600c514-0c7c-4401-d09f-1c9b44ba9332",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from CodleAI import AIProject3\n",
    "\n",
    "map = [\"SFFFFF\",\n",
    "       \"FHFHHF\",\n",
    "       \"FHFFHF\",\n",
    "       \"HFFFFG\"]\n",
    "\n",
    "AIProject3(map)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "read_only": true,
  "vscode": {
   "interpreter": {
    "hash": "8c352b738e5f22da9f29eb9cb9994f25c5223ab3395af3650b8321ab644afce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
